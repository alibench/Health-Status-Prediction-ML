{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "%matplotlib inline\n",
    "import numpy as numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "data_path = \"data/dataset/\"\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(data_path ,sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((328135, 321), (109379, 321), (328135,), (328135,), (109379,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View shape of the dataset\n",
    "x_train.shape, x_test.shape, y_train.shape, train_ids.shape, test_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 321 features.\n",
    "- `x_train` contains the training data and it has 328 135 data entries (before cleaning).\n",
    "- `x_test` contains the test data and it has 109 379 data entires (before cleaning).\n",
    "- The `y` vector corresponds to the true values of the output (the variable we wish to predict). The output describes whether a person is diagnosed with MICHD or not. It is binary, -1 or +1, where -1 means no MICHD and +1 means MICHD. There are 328 135 data points (before cleaning).\n",
    "- `train_ids` and `test_ids` are numpy arrays. Their values correspond to the ids of the data entries of train data and test data, respectively. Therefore, the length of `train_ids` and `test_ids` correspond to the number of data entries for both train and test data, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.3000000e+01 1.1000000e+01 1.1162015e+07 ...           nan\n",
      "            nan 2.0000000e+00]\n",
      " [3.3000000e+01 1.2000000e+01 1.2152015e+07 ...           nan\n",
      "            nan           nan]\n",
      " [2.0000000e+01 1.0000000e+01 1.0202015e+07 ... 1.0000000e+00\n",
      "  2.0000000e+00 2.0000000e+00]\n",
      " [4.2000000e+01 6.0000000e+00 6.1820150e+06 ... 2.0000000e+00\n",
      "  2.0000000e+00 2.0000000e+00]\n",
      " [2.4000000e+01 1.1000000e+01 1.1062015e+07 ... 9.0000000e+00\n",
      "  9.0000000e+00 2.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# View the few first and last rows of the dataset\n",
    "print(x_train[:5])  # First 5 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.9000000e+01 7.0000000e+00 1.1232015e+07 ...           nan\n",
      "            nan 2.0000000e+00]\n",
      " [5.1000000e+01 5.0000000e+00 6.0820150e+06 ...           nan\n",
      "            nan 1.0000000e+00]\n",
      " [3.9000000e+01 1.0000000e+01 1.0202015e+07 ... 2.0000000e+00\n",
      "  2.0000000e+00 2.0000000e+00]\n",
      " [3.3000000e+01 1.2000000e+01 1.2302015e+07 ...           nan\n",
      "            nan 2.0000000e+00]\n",
      " [3.2000000e+01 9.0000000e+00 9.1220150e+06 ...           nan\n",
      "            nan 2.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[-5:])  # Last 5 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note which features are categorical/continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Rid of Useless Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out which features are unimportant, we take a look at the column names of the dataset.\n",
    "\n",
    "After taking a closer look at the features, we decide to remove the columns as done below. They were removed for either of these reasons:\n",
    "- The columns were not relevant to the goal of our project (e.g. State, Income, etc.)\n",
    "- The columns represented questions about a specific subject that were later regrouped into a single feature (e.g. for Cholesterol, many questions were asked to the participants. One final feature summarized the findings. We only keep this final feature.)\n",
    "- The columns had too many null values, becoming irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new = x_train.copy()\n",
    "columns_to_remove = range(50)  # Indices of columns to remove\n",
    "x_train_new = np.delete(x_train_new, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = range(1, 14)  # Indices of columns to remove\n",
    "x_train_new = np.delete(x_train_new, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = range(2, 44)  # Indices of columns to remove\n",
    "x_train_new = np.delete(x_train_new, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = range(13, 37)  # Indices of columns to remove\n",
    "x_train_new = np.delete(x_train_new, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = range(16, 37)  # Indices of columns to remove\n",
    "x_train_new = np.delete(x_train_new, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = range(42, 56)  # Indices of columns to remove\n",
    "x_train_new = np.delete(x_train_new, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = range(52, 66)  # Indices of columns to remove\n",
    "x_train_new = np.delete(x_train_new, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [78, 79, 80]  # Indices of columns to remove\n",
    "x_train_new = np.delete(x_train_new, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new = np.delete(x_train_new, 72, axis=1) # remove height in inches to only keep height in meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of columns that have too many null values\n",
    "\n",
    "x_train_clean = x_train_new.copy()\n",
    "max_nan_threshold = 50000 # specify the threshold for the maximum allowed NaN values in a column\n",
    "nan_counts =  np.isnan(x_train_new).sum(axis=0) #count the number of NaN values in each column\n",
    "columns_to_keep = nan_counts <= max_nan_threshold # Identify columns to keep (those that have NaN counts below the threshold)\n",
    "x_train_clean = x_train_clean[:, columns_to_keep] # Remove columns with too many NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 70)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves us with 70 features. Let's ignore take a closer look at the features left. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0, 43801,     0,     0,     0,\n",
       "        1883,     0,     0,     0,     0,     0,     0,  5438,     0,\n",
       "           0,     0,     0, 11368, 23006, 27073, 27073,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0, 28366, 26927, 29382,\n",
       "       27893, 28958, 30593,     0,     0,     0,     0, 32115, 37605,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "       32496,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,  1883,  1883,  1883,     0,     0, 32080])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x_train_clean).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we specify the index of the column, its name, the number of NaNs it contains, and the type of feature. If not specified, there are no NaNs.\n",
    "- 2: health coverage. Type of health coverage, if it exists. **(Not relevant to this problem, can be removed)**\n",
    "- 4: Cholesterol Check. How long it has been since last cholesterol check. **(Not relevant to this problem, can be removed)**\n",
    "- 5,6: Asthma. Adults who have been told they formerly or currently have asthma.  **(Not relevant because the information is summarized in another variable)**\n",
    "- 11,12,13,14,15: Race **(Not relevant because the information is summarized in another variable)**\n",
    "- 28,29,30,31: drinking categories. **(Not relevant because the information is summarized in another variable)**\n",
    "- 69: Tested for HIV. Measures whether the participant has been tested for HIV, but doesn't give information on whether they have been diagnoses. **(Not relevant to this problem, can be removed)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 56)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_final = x_train_clean.copy()\n",
    "columns_to_remove = [2, 4, 7, 8, 11, 12, 13, 14, 15, 28, 29, 30, 31, 69] # Indices of columns to remove\n",
    "x_train_final = np.delete(x_train_final, columns_to_remove, axis=1)\n",
    "\n",
    "x_train_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we specify the index of the column, its name, and we describe what it measures.\n",
    "- 0: sex. Categorical: 1 for male, 2 for female.\n",
    "- 1: health status. Categorical: 1 for good or better health, 2 for fair or poor health. \n",
    "- 2: Blood pressure levels. Categorical: 1 for low blood pressure, 2 for high blood pressure.\n",
    "- 3: level of cholesterol, 43 801 NaNs. Categorical: 1 for low cholesterol, 2 for high cholesterol.\n",
    "- 4: CHD or MI. Categorical: 1 for reported having MI or CHD, 2 if not.\n",
    "- 5: asthma status, 1883 NaNs. Categorical: 1 current asthma, 2 former asthma, 3 no asthma.\n",
    "- 6: Arthritis. Categorical: 1 diagnosed for arthiritis, 2 if not.\n",
    "- 7: race groups, 5438 NaNs. Categorical: 1 White - Non-Hispanic, 2 Black - Non-Hispanic, 3 Hispanic, 4 Other race only - Non-hispanic, 5 Multiracial, Non-Hispanic.\n",
    "- 8,9,10,11: Age categories. Different categorizations of Age. We keep them all to choose later.\n",
    "- 12: height in meters, 11 368 NaNs.\n",
    "- 13,14,15: weight in kg, BMI and 4 categories of BMI. They all have around 25 000 NaNs. We keep them all to choose later.\n",
    "- 16: BMI categories. We keep them all to choose later.\n",
    "- 17,18: smoke categories. We keep them both to choose later.\n",
    "- 19: Heavy drinkers. Categorical: 1 if not heavy drinker, 2 if heavy drinker.\n",
    "- 20 -> 25: fruits and vegetable consumption information, all have aroung 30 000 NaNs.\n",
    "- 26,27,28,29: Same\n",
    "- 30, 31: Same, all have around 30 000 NaNs.\n",
    "- 32 -> 40: Exercise information\n",
    "- 41: Exercise information, 32 496 NaNs.\n",
    "- 42 -> 50: Same\n",
    "- 51, 52, 53: Same, each have 1883 NaNs.\n",
    "- 54, 55: Same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical vs continuous\n",
    "#set a threshold of unique values and say that those who have less than ... unique values are categorical and the rest are continuosu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
